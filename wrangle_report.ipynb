{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73246f1-cb38-4767-be1b-cc9fa057888f",
   "metadata": {},
   "source": [
    "# Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795370da-011b-431a-b372-b385d3e5271e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "The aim of the project is to gather, access and clean data, to create reliable analysis. The data for the project is the tweet archive of  `@dog_rates`, also known as `WeRateDogs`. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "The initial WeRateDogs twitter archive doesn't contain all the required information/variables for this project. Such variables include `number of retweet`, `number of likes`. This variables are very important for this analysis, hence I used the Twitter API to query this additional data\n",
    "\n",
    "Additionally, an `image_prediction.txt`  file was  provided. The content is the result from a neural network that can classify breeds of dogs.The file is full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images). This file was  downloaded programmatically\n",
    "\n",
    "Therefore, the aim is to gather these and convert it into a high-quality data, reliable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af1e6a-6dbc-4926-b178-d008e5b64578",
   "metadata": {},
   "source": [
    "## What was done to achieve the result ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469f466-1996-493b-ae57-8a6d73fedbab",
   "metadata": {},
   "source": [
    "First, I needed to make sure I have all the three data available in my workspace for wrangling. The `WeRateDog` twitter  archive was already available. I had to collect the remaining two programmatically:\n",
    "- the `image_prediction.tvs` file was downloaded using the python request library\n",
    "- the remaining information/variables needed for this project such as `retweet_count` and `favorite_count` was collected using the Twitter API and the tweepy library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25525937-d4fe-4aa2-b447-e97640dbd2c2",
   "metadata": {},
   "source": [
    "After collecting the data, I assessed it visually and programmatically to find out Quality and Tidiness issues. Some of the issues identified were:\n",
    "- Nan values in most of the columns\n",
    "- some columns datatype was not correct. e.g the timestamp column\n",
    "- most of the columns are not neccessay for the analysis\n",
    "- some tweets were not original. some were retweets\n",
    "- some tweets do not contain dog images. The analysis only require tweets for which the image is a dog\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca386c-a790-4159-8304-2f34feabc224",
   "metadata": {},
   "source": [
    "After identifying key Quality and Tidiness issues, the next step was to clean it. I utilized the pandas library in getting the data in the right format and structure by solving those issues identified. \n",
    "\n",
    "The cleaned data was stored as a comma-seperated file (csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
